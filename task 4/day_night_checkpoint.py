# -*- coding: utf-8 -*-
"""Day_Night-checkpoint.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14IS6iSSV_q_RgKM_GKPiem8W9Yx2hfyq
"""

from __future__ import print_function, division
import numpy as np
import pandas as pd
import scipy
from glob import glob
import numpy as np
import matplotlib.pyplot as plt
from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate
from keras.layers import BatchNormalization, Activation, ZeroPadding2D
from keras.layers.advanced_activations import LeakyReLU
from keras.layers.convolutional import UpSampling2D, Conv2D
from keras.models import Sequential, Model
from keras.optimizers import Adam
import datetime
import sys
import os
import cv2
from skimage import transform
from imageio import imread

!wget  http://transattr.cs.brown.edu/files/aligned_images.tar

!tar -xvf aligned_images.tar

#Hyperparameters

#Output Shape
resolution = (256,256)

# Input shape
img_rows = 256
img_cols = 256
channels = 3
img_shape = (img_rows, img_cols, channels)

# Size of Patch for PatchGAN
patch = int(img_rows / 2**2)
disc_patch = (patch, patch, 1)

# Number of filters for G and D
filters_gen = 64

#Optimizer for the GAN.
optimizer = Adam(0.0002, 0.5)

# def load_images(dataset,batch_size):
#     chance = np.random.random()
#     path = glob('cityscapes/train/*')
#     images = np.random.choice(path, size=batch_size)
#     img_real = []
#     img_labelled = []

#     for imagepath in images:
#         img = cv2.imread(imagepath)
#         width = img.shape[1]
#         width = width//2
#         real_img, labelled_img = img[:, width:, :],img[:, :width, :]
#         real_img,labelled_img = transform.resize(real_img, resolution),transform.resize(labelled_img, resolution)
#         if (chance<0.5):
#             real_img = np.fliplr(real_img)
#             labelled_img = np.fliplr(labelled_img)
#         img_real.append(real_img)
#         img_labelled.append(labelled_img)
#     return np.array(img_labelled),np.array(img_real)

def load_data(batch_size=1, is_testing=False):
    data_type = "train" if not is_testing else "test"
    #path = glob('./datasets/%s/%s/*' % (self.dataset_name, data_type))

    #batch_images = np.random.choice(path, size=batch_size)

    rootdir = 'imageAlignedLD/'
    imgs_A = []
    imgs_B = []
    for img_path in range(batch_size):
        img_A = imread(rootdir+day[img_path][1])
        img_B = imread(rootdir + day[img_path][0])

        #h, w, _ = img.shape
        #_w = int(w/2)
        #img_A, img_B =

        img_A = scipy.misc.imresize(img_A, resolution)
        img_B = scipy.misc.imresize(img_B, resolution)

        # If training => do random flip (flip the rows)
        if not is_testing and np.random.random() < 0.5:
            img_A = np.fliplr(img_A)
            img_B = np.fliplr(img_B)

        imgs_A.append(img_A)
        imgs_B.append(img_B)

    imgs_A = np.array(imgs_A)/127.5 - 1.
    imgs_B = np.array(imgs_B)/127.5 - 1.

    return imgs_A, imgs_B
#     return np.array(img_labelled), np.array(img_real)

# REMEBER! - arr1(A) is the actual truth. arr2(B) is the labelled graphical image

# for batch_i, (imgs_A, imgs_B) in enumerate(load_images(1,2)):
#     print("hey")
#arr1,arr2 = load_images('1',32,12)
# arr1.shape

def new_generator():
    layer0 = Input(shape=img_shape,name="input")
    layer1 = Conv2D(filters_gen, kernel_size=4,strides = 2,activation = LeakyReLU(alpha=0.2),padding='same')(layer0)
    bd = BatchNormalization(momentum=0.8)(layer1)
    layer2 = Conv2D(filters_gen*2, kernel_size=4,strides = 2,activation = LeakyReLU(alpha=0.2),padding='same')(bd)
    bd = BatchNormalization(momentum=0.8)(layer2)
    layer3 = Conv2D(filters_gen*4, kernel_size=4,strides = 2,activation = LeakyReLU(alpha=0.2),padding='same')(bd)
    bd = BatchNormalization(momentum=0.8)(layer3)
    layer4 = Conv2D(filters_gen*8, kernel_size=4,strides = 2,activation = LeakyReLU(alpha=0.2),padding='same')(bd)
    bd = BatchNormalization(momentum=0.8)(layer4)
    layer5 = Conv2D(filters_gen*8, kernel_size=4,strides = 2,activation = LeakyReLU(alpha=0.2),padding='same')(bd)
    bd = BatchNormalization(momentum=0.8)(layer5)
    layer6 = Conv2D(filters_gen*8, kernel_size=4,strides = 2,activation = LeakyReLU(alpha=0.2),padding='same')(bd)
    bd = BatchNormalization(momentum=0.8)(layer6)
    dropout = Dropout(0.10)(bd)
    layer7 = Conv2D(filters_gen*8, kernel_size=2,strides = 2,activation = LeakyReLU(alpha=0.2),padding='same')(dropout)
    bd = BatchNormalization(momentum=0.8)(layer7)
    def deconv2d(prev_layer, skip_input, filters):
        temp = UpSampling2D(size=2)(prev_layer)
        temp = Conv2D(filters, kernel_size=4, strides=1, padding='same', activation='relu')(temp)
        temp = BatchNormalization(momentum=0.6)(temp)
        temp = Concatenate()([temp, skip_input])
        return temp

    u_layer1 = deconv2d(bd, layer6, filters_gen*8)
    u_layer2 = deconv2d(u_layer1, layer5, filters_gen*8)
    u_layer3 = deconv2d(u_layer2, layer4, filters_gen*8)
    u_layer4 = deconv2d(u_layer3, layer3, filters_gen*4)
    dropout = Dropout(0.25)(u_layer4)
    u_layer5 = deconv2d(dropout, layer2, filters_gen*2)
    u_layer6 = deconv2d(u_layer5, layer1, filters_gen)
    u_layer7 = UpSampling2D(size=2)(u_layer6)
    u_layer0 = Conv2D(channels, kernel_size=4, strides=1, padding='same', activation='tanh')(u_layer7)
    return Model(layer0,u_layer0,name="Generator")


def new_discriminator():
    def d_layer(prev_layer, filters):
        print(filters)
        temp = Conv2D(filters, kernel_size=4, strides=2, padding='same')(prev_layer)
        temp = LeakyReLU(alpha=0.2)(temp)
        return temp

    layer0_A = Input(shape=img_shape)
    layer0_B = Input(shape=img_shape)
    combined_input = Concatenate(axis=-1)([layer0_A, layer0_B])
    layer1 = d_layer(combined_input, filters_gen)
    layer2 = d_layer(layer1, filters_gen*2)
    #layer3 = d_layer(layer2, filters_gen*4)
    #layer4 = d_layer(layer3, filters_gen*4)
    dropout = Dropout(0.25)(layer2)
    layer5 = Conv2D(1, kernel_size=4, strides=1, padding='same')(dropout)
    return Model([layer0_A, layer0_B], layer5,name="Discriminator")

heaven = new_discriminator()
heaven.summary()

'''
1. Two images as input.
2. One image goes to generator
3. Two images go to the discriminator as input
4. We freeze the discriminator weights
5. Create GAN with both models. Inputs - B (Labelled Graphical) as earlier and outputs (A - Ground Truth) as earlier
'''
#<---Since the model is being compiled already here,
# the flag later of trainable = False does not affect it.--->
d = new_discriminator()
d.compile(loss='mse',
            optimizer=optimizer,
            metrics=['accuracy'])


g = new_generator()

input_image_A = Input(shape = img_shape)
input_image_B = Input(shape = img_shape)

fake_image_B = g(input_image_B)
validity = d([fake_image_B,input_image_B])

#THIS ONLY STOPS THE TRAINING OF THE DISCRIMINATOR IN THE GAN. IT WILL STILL TRAIN WHEN INVOKED AS JUST D.
d.trainable = False

gan = Model(inputs=[input_image_A,input_image_B],outputs = [validity,fake_image_B],name="GAN")

gan.compile(loss=['mse', 'mae'],
                              loss_weights=[1, 100],
                              optimizer=optimizer)
gan.summary()

def plot_img():
    truth,labelled = load_images(1,1,1)
    predict = g.predict(labelled)
    plt.imshow((predict[0] * 255).astype(np.uint8))
    plt.show()
    plt.imshow(truth[0])
    plt.show()

def train(epochs,batch_size):
    valid_scores = np.ones((batch_size,disc_patch[0],disc_patch[1],disc_patch[2]))
    fake_scores = np.zeros((batch_size,disc_patch[0],disc_patch[1],disc_patch[2]))
    for j in range(epochs):
        print("Epoch -",j+1)
        start = datetime.datetime.now()
        for i in range(0,31):
# begin
            images_A,images_B = load_images(1,batch_size,i)
            fake_images = g.predict(images_B)

            #Discriminator losses
            d_loss_real = d.train_on_batch([images_A,images_B],valid_scores)
            d_loss_fake = d.train_on_batch([fake_images,images_B],fake_scores)
            avg_d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)
            #GAN losses
            gan_loss = gan.train_on_batch([images_A,images_B],[valid_scores,images_A])
# end
        print("Discriminator Loss = ",avg_d_loss[0], "Accuracy =",avg_d_loss[1]*100)
        print("GAN Loss = ",gan_loss[0])
        end = start_time = datetime.datetime.now()
        print("Time Elapsed",end-start,"\n")
        if(j%5==0):
            plot_img()
#     return avg_d_loss, gan_loss

import warnings
warnings.filterwarnings("ignore")
train(200,1)

train(100,1)

train(50,1)

def load_images(dataset,batch_size,epoch):
    chance = np.random.random()
    #path = glob('cityscapes/train/*')
#     images = np.random.choice(path, size=batch_size)
    images = day[epoch*batch_size:(epoch+1)*batch_size]
    img_real = []
    rootdir = 'imageAlignedLD/'
    img_labelled = []
    for imagepath in images:
        real_img = imread(rootdir+imagepath[0])
        labelled_img = imread(rootdir+imagepath[1])
        #width = img.shape[1]
        #width = width//2
        #real_img, labelled_img = img[:, width:, :],img[:, :width, :]
        real_img,labelled_img = transform.resize(real_img, resolution),transform.resize(labelled_img, resolution)
        if (chance<0.5):
            real_img = np.fliplr(real_img)
            labelled_img = np.fliplr(labelled_img)
        img_real.append(real_img)
        img_labelled.append(labelled_img)
    if(dataset=='55'):
        return np.array(img_real), np.array(img_labelled)
    return np.array(img_labelled), np.array(img_real)

'''
# REMEBER! - arr1(A) is the actual truth. arr2(B) is the labelled graphical image

# for batch_i, (imgs_A, imgs_B) in enumerate(load_images(1,2)):
#     print("hey")
arr1,arr2 = load_images('1',32,12)
# arr1.shape

# Testing the GAN

for i in range(0,10):
    truth,labelled = load_images_test('edges2shoes',1,i+100)
    predict = g.predict(labelled)
    plt.imshow(predict[0])
    plt.show()
    plt.imshow(truth[0])
    plt.show()'''

import pandas as pd
import numpy as np

#print(np.unravel_index(np.argmax(dist), dist.shape))

df = pd.read_csv('annotations.tsv', usecols=[0,2,3], names=['image', 'sunny', 'night'], header=None, sep = '\t')
df['fol']= [x.split('/')[0] for x in df['image'].tolist()]

df.head()

day = []
b = df.groupby('fol')
for i,j in b:
    a = j['image'].tolist()[np.unravel_index(np.argmax(np.array(j['sunny'].tolist())), np.array(j['sunny'].tolist()).shape)[0]]
    c = j['image'].tolist()[np.unravel_index(np.argmax(np.array(j['night'].tolist())), np.array(j['night'].tolist()).shape)[0]]
    day.append([a,c])
print(day)

!pip install -U -q PyDrive
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials

auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

g.save_weights('D2Ngen.h5')
model_file = drive.CreateFile({'title' : 'D2Ngen.h5'})
model_file.SetContentFile('D2Ngen.h5')
model_file.Upload()

heaven.save_weights('D2Ndisc.h5')
model_file = drive.CreateFile({'title' : 'D2Ndisc.h5'})
model_file.SetContentFile('D2Ndisc.h5')
model_file.Upload()

